<!doctype>
<html>
<head>

	<title>Explicability</title>

	<!-- Meta -->
	<meta content="text/html;charset=utf-8" http-equiv="Content-Type">
	<meta content="utf-8" http-equiv="encoding">
	<meta charset="utf-8">
	<meta name="viewport" content="width=450">
	<link rel="icon" type="image/png" href="favicon.png"/>

	<!-- Stylin' -->
	<link rel="stylesheet" href="index.css"/>


</head>
<body>

	<div id="content">

		<p>
			I make transparent models for regression and classification problems, mainly in the Insurance space. If you need something along those lines, contact me at <i>explicability at protonmail dot com</i>.
		</p>
		
		<h1>Explicable Modelling</h1>
		
		<h2>Tailored Modelling</h2>
		<p>I wrote the open-source interpretable modelling library <a href="github.com/H-B-P/DURKON">Durkon</a> from scratch, using nothing more complicated than NumPy and Pandas. Because it’s my own work, I know exactly how to modify and extend it to fit your organisation’s unique needs.</p>
		<p><i>"Hugh is the best I've ever worked with at certain invaluable things: he thinks from first principles and covers all of the many ways that ML training and deployment goes wrong. I've seen him implement unprecedented techniques by hand, all the while watching for the actual business effect behind the metrics." - Gavin Leech, AI Researcher, cofounder of Arb Research</i></p>
		<h2>Inherent Interpretability</h2>
		<p>All Durkon models can be represented as a collection of Partial Dependency Plots and/or Relativity Tables. This means the decisions they make will always be easy to explain to your clients / customers / regulators / underwriters / superiors / subordinates / self.</p>
		<img src="Color_of_Car.png"height=250 width=350><img src="Age_of_Drivers_Pet_Dog.png"height=250 width=350>
		<h2>Eloquent Documentation</h2>
		<p>I am that most wondrous of things, an engineer who knows how to communicate. I wrote everything on this website; I’ll write the documentation for my work in a similar style and to a similar standard.</p>
		<p><i>"Hugh's documentation is clear, concise, and geniunely pleasant to read." - James Blackham, CEO, By Miles</i></p>
		<h2>Optional Extras</h2>
		<br>
		<table>
		 <tr>
		  <th></th>
		  <th><b>You provide:</b></th>
		  <th><b>You recieve:</b></th>
		 <tr>
		  <td class="explanation"><b>Free Demo:</b> You may find it hard to believe that one rogue scientist can model better and faster than industry leaders. My response to such flattering suspicion is to echo famed epistemologist Benjamin “Macklemore” Haggerty: <i>don’t believe me, just watch</i>. If you want to know I can handle whatever problem your company is facing, select or generate an appropriate dataset and I’ll use it to demonstrate how well my tools work.</td>
		  <td><ul>
		   <li>A dataset you selected or generated.</li>
		   <li>Details of the model you’d need.</li>
		  </ul></td>
		  <td><ul>
		   <li>A model built using that dataset.</li>
		   <li>Confidence that Explicability is the right choice for your business.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>“Willis Towers Holmes” Guarantee:</b>  Every time I’ve seen a model made by Willis Towers Watson, or using their software, it’s turned out to have several things profoundly wrong with it. If you’re using a WTW model, I guarantee I can provide something that does the same job better.</td>
		  <td><ul>
		   <li>Whatever you gave WTW and/or your Emblem modelling team.</li>
		   <li>Whatever they gave you in return.</li>
		  </ul></td>
		  <td><ul>
		   <li>A better model.</li>
		   <li>A detailed explanation of everything wrong with your current model.</li>
		   <li>. . . or your money back!</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Personnel Training: </b>Most clients just want models and model-producing scripts. However, if you’re interested in developing in-house talent for using Durkon, I'd be <i>very</i> happy to talk through my approach in greater detail.</td>
		  <td><ul>
		   <li>Someone who knows Python, NumPy, and Pandas to an acceptable level.</li>
		  </ul></td>
		  <td><ul>
		   <li>Someone who knows exactly as much as they need to know about Durkon modelling.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Model Adjustment: </b>You may have a model you want to update for a new context, or to which you want to add a handful of new features, while leaving most of the structure intact. If so, this is a very strange thing to want and I don’t understand why you wouldn’t just refit the entire model. However, the performance of this bizarre ritual is something I’m quite capable of helping you with</td>
		  <td><ul>
		   <li>Your current model’s predictions on a training dataset.</li>
		   <li>A list of features I should use for adjustments.</li>
		  </ul></td>
		  <td><ul>
		   <li>A list of suggested adjustments.</li>
		   <li>A perplexed expression.</li>
		   <li>A sincere attempt to work out why you insist on doing things this way.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Novel Constraints: </b>Do you want some features to have monotonic effects on the predicted outcome? Are there columns which should never produce a >30% change to the final prediction? Is there some other limitation that you want your model optimized around? Let me know, and I’ll build something which ticks all your boxes without crossing any of your red lines.</td>
		  <td><ul>
		   <li>A list of things you want the model (not) to do.</li>
		  </ul></td>
		  <td><ul>
		   <li>A model which does(n’t) do those things.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Feature Selection: </b>Data costs money, and using more of it complicates models while increasing regulatory burdens. My modelling approach allows me to use Grouped Lasso Penalization – combined with common sense – to make sure models only the features they need.</td>
		  <td><ul>
		   <li>Guidelines for how to make the tradeoff between performance and feature count (“use the 15 most useful features”, “use as few externally-sourced features as possible”, etc).</li>
		  </ul></td>
		  <td><ul>
		   <li>A model built using those guildelines.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>GBT Benchmarking: </b>In addition to being a specialist in interpretable modelling, I also know how to use standard ML libraries. While benchmarking should ideally be handled in-house (otherwise, I’m marking my own work), if you want me to build an XGBoost model to compare my Durkon model to, that’s not a problem on my end.</td>
		  <td><ul>
		   <li>A frankly inexplicable level of faith in my integrity.</li>
		  </ul></td>
		  <td><ul>
		   <li>An XGB model which does the same thing my legible model does.</li>
		   <li>Comparisons between the Durkon and XGB models on key performance metrics.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Drift Correction: </b>When context changes, models become systematically less accurate. Absent correction, high predictions will in general be too high, and low predictions will in general be too low.* If you expect a multi-year lag – or any other kind of change in context – between getting your data and deploying the model built on it, I can adjust for expected model decay.</td>
		  <td><ul>
		   <li>Data from X years ago.</li>
		   <li>Data from 2X years ago.</li>
		   <li>Ideally, data from 3x and 4x years ago. </li>
		  </ul></td>
		  <td><ul>
		   <li>A model which avoids systematic biases towards extreme predictions when predicting in today’s context.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Error Modelling: </b>Model accuracy can be represented numerically. Things which can be represented numerically can be modelled. Therefore, it’s possible to model how accurate your model will be, predict which predictions are most credible, and provide that information alongside the predictions themselves.</td>
		  <td><ul>
		   <li>A dataset where the response variable is predictable enough from the explanatory variables that error modelling is feasible.</li>
		  </ul></td>
		  <td><ul>
		   <li>An error-predicting model which predicts how accurate the main model will be for each row.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Tobit Modelling for Censored Data: </b>Sometimes**, part or all of your response column will not be of the form “[thing you want to predict]=x”, and will instead be of the form “[thing you want to predict] is greater/less than x”. I’ve spent quite some time figuring out exactly how to best work around this kind of censorship, and I’d be very interested in sharing my expertise.</td>
		  <td><ul>
		   <li>A dataset with censored response variables.</li>
		   <li>An indication of which rows are censored and how.</li>
		  </ul></td>
		  <td><ul>
		   <li>A model which makes accurate and unbiased predictions despite that censorship.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Flexible Deployment: </b>Durkon models are simple and intuitive enough that they can easily be converted into Emblem and other formats by hand, and low-dependency enough that they can be deployed in any backend with Python, NumPy and Pandas. However, if you want model output to automatically take a particular shape, I’m happy to oblige.</td>
		  <td><ul>
		   <li>An example of the target model format.</li>
		  </ul></td>
		  <td><ul>
		   <li>A Durkon model expressed in that model format.</li>
		   <li>A tool for converting Durkon models to that model format.</li>
		  </ul></td>
		 </tr>
		 
		 <tr>
		  <td class="explanation"><b>Custom Options: </b>Want something that’s not in this table? Tell me, and I’ll look into it. And if it’s something that seems like it’d be a good addition to Durkon, I’ll build it for free and release it as open-source.</td>
		  <td><ul>
		   <li>A new challenge.</li>
		  </ul></td>
		  <td><ul>
		   <li>Creativity, ingenuity, and dedication.</li>
		  </ul></td>
		 </tr>
		 
		</table>
		
		<p class=footnote>*To see why this is true, consider the pathological case where changes in context are so extreme that your model is uncorrelated with reality: if you guess people’s heights randomly, the people you expect to be tall will be on average shorter than you expect, and the people you expect to be short will be on average taller than you expect.</p>
		<p class=footnote>**For example, when modelling market trends in sealed-bid first-place auctions if you only have the winning bids and are already part of the market.</p>
		
		<h1>Other Work</h1>
		<h2>Model Fisking</h2>
		<p>Somehow, not everyone who goes to the trouble of making an explicable model finds time to explicate it. If you already have a transparent model – i.e., anything built using Excel or Emblem – I can look through it for you, and produce a list of suboptimalities / potential regulatory issues / just-plain-weirdness for you to address.</p>
		<h2>D+D.Sci</h2>
		<p>I make Data Science challenges and release them for free <a href="https://www.lesswrong.com/s/gDiScDuMrWNpzwNSJ">online</a>. This is more of a hobby and advertising strategy than it is a service, but if you offered me large amounts of money to write a challenge tailored to your requirements I wouldn’t say no.</p>
		<h2>Conceptual Proofreading</h2>
		<p>I like editing things, and I’m pretty good at it. If you want me to look through a document for mistakes – grammatical, stylistic, factual, logical, strategic, or moral – I’d charge very reasonable rates. (. . . by Data Science standards, at least.)</p>


	</div>

	<div id="footer">

		<br>

	</div>

</body>
</html>
